{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f8701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from game import Snake\n",
    "import os\n",
    "import wandb\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34237980",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c3ed813",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1 \n",
    "EPSILON_DECAY = 0.095\n",
    "ACTION_SPACE = [0,1,2,3]\n",
    "GAMMA = 0.99\n",
    "LR = 1e-3\n",
    "INPUT_SIZE = 8\n",
    "OUTPUT_SIZE = 5 \n",
    "# HIDDEN_SIZE = 64 \n",
    "EPOCHS = 1000\n",
    "FREQ_OF_TARGET_NN_UPDATE = 20\n",
    "REPLAY_MEMORY_SIZE = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6fdb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ca699",
   "metadata": {},
   "source": [
    "### Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b21302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(epsilon, action_space, highest_estimated_action):\n",
    "    if random.random() < epsilon:\n",
    "        return random.randint(0, len(action_space) - 1)\n",
    "    else: \n",
    "        return highest_estimated_action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9cad1",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045114a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(active_prediction, gamma, immediate_reward, action, done, final_state, target_nn):\n",
    "    active_prediction = active_prediction[action]\n",
    "    if done == True: \n",
    "        q_target = immediate_reward\n",
    "    else:\n",
    "        next_state_value_target = target_nn(torch.tensor(final_state, dtype=torch.float32).to(device))[action]\n",
    "        q_target = immediate_reward + (gamma * next_state_value_target) \n",
    "        \n",
    "    loss = (q_target - active_prediction) ** 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce06bf4",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80714297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[head_x, head_y, direction, food_x, food_y, danger_straight, danger_right, danger_left]\n",
    "class DQN_base_ff(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    def save(self, file_name=\"model.pth\"):\n",
    "        model_folder_path = \"./model\"\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "        \n",
    "        file_name = os.path.join(model_folder_path, file_name)\n",
    "        torch.save(self.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0237f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[head_x, head_y, direction, food_x, food_y, danger_straight, danger_right, danger_left]\n",
    "class DQN_scaled_ff(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size) -> None:\n",
    "        super().__init__()\n",
    "        hidden_size1 = int(hidden_size * 2)\n",
    "        hidden_size2 = int(hidden_size / 2)\n",
    "        \n",
    "        self.input_linear = nn.Linear(input_size, hidden_size)\n",
    "        self.linear_sequence1 = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size1),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_size1, hidden_size1),\n",
    "            nn.Linear(hidden_size1, hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size1, hidden_size1),\n",
    "            nn.Linear(hidden_size1, hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size1, hidden_size1)\n",
    "        )\n",
    "        self.linear_sequence2 = nn.Sequential(\n",
    "            nn.Linear(hidden_size1, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size2),\n",
    "            nn.Linear(hidden_size2, hidden_size2),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_size2, hidden_size2),\n",
    "            nn.Linear(hidden_size2, hidden_size2),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_size2, hidden_size2)\n",
    "        )\n",
    "        self.output_linear = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_linear(x) \n",
    "        x = self.linear_sequence1(x)\n",
    "        x = self.linear_sequence2(x)\n",
    "        x = self.output_linear(x)\n",
    "        return x\n",
    "    \n",
    "    def save(self, file_name=\"model.pth\"):\n",
    "        model_folder_path = \"./model\"\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "        \n",
    "        file_name = os.path.join(model_folder_path, file_name)\n",
    "        torch.save(self.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee01b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(size, state_action_pairs):\n",
    "    indices = random.sample(range(len(state_action_pairs)), size)\n",
    "    batch = [state_action_pairs[i] for i in indices]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffac04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(active_nn, target_nn, state_action_pairs, replay_memory_size, device, loss_function, optimizer, gamma, epochs, freq_of_target_nn_update, epsilon, action_space, policy, model_name, model_type, learning_rate, run_name, save_model=False):\n",
    "    wandb.init(\n",
    "        project=\"snake_game_rl\",\n",
    "        name=run_name,\n",
    "        config={\n",
    "            \"model_name\": model_name,\n",
    "            \"model_type\": model_type,\n",
    "            \"epsilon\": epsilon,\n",
    "            \"gamma\": gamma,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"replay_memory_size\": replay_memory_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"freq_of_target_nn_update\": freq_of_target_nn_update,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    training_table = wandb.Table(columns=[\"epoch\", \"loss\"])\n",
    "    evaluation_table = wandb.Table(columns=[\"epoch\", \"steps\", \"score\"])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_sample_batch = state_action_pairs[random.randint(0, replay_memory_size - 1)]\n",
    "        optimizer.zero_grad() \n",
    "        input = torch.tensor(train_sample_batch[0], dtype=torch.float32).to(device)\n",
    "        action_pred = active_nn(input)\n",
    "        loss = loss_function(action_pred, gamma, train_sample_batch[2], train_sample_batch[1], train_sample_batch[4], train_sample_batch[3], target_nn)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_value = loss.item()\n",
    "        \n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"training_loss\": loss_value\n",
    "        })\n",
    "        \n",
    "        training_table.add_data(str(epoch), str(loss_value))\n",
    "        \n",
    "        print(f\"Epoch {epoch}, Loss: {loss_value}\")\n",
    "    \n",
    "        if epoch % freq_of_target_nn_update == 0:\n",
    "            target_nn.load_state_dict(active_nn.state_dict())\n",
    "            target_nn.requires_grad_ = False\n",
    "\n",
    "            print(\"Evaluating active network\")\n",
    "            steps = 0\n",
    "            score = 0\n",
    "            evaluation_game = Snake(evaluation=True)\n",
    "            \n",
    "            while True:\n",
    "                initial_state = evaluation_game.get_state()\n",
    "                action_pred = active_nn(torch.tensor(initial_state, dtype=torch.float32).to(device))\n",
    "                action = policy(0, action_space, torch.argmax(action_pred))\n",
    "                done = evaluation_game.move_with_action(action=action)\n",
    "                steps += 1\n",
    "                \n",
    "                if evaluation_game.get_immediate_reward() == 1:\n",
    "                    score += 1\n",
    "                \n",
    "                if done == True:\n",
    "                    break\n",
    "            \n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"evaluation_steps\": steps,\n",
    "                \"evaluation_score\": score\n",
    "            })\n",
    "            \n",
    "            evaluation_table.add_data(str(epoch), str(steps), str(score))\n",
    "            \n",
    "            print(f\"Evaluation - Steps: {steps}, Score: {score}\")\n",
    "    \n",
    "    wandb.log({\"training_metrics_table\": training_table})\n",
    "    wandb.log({\"evaluation_metrics_table\": evaluation_table})\n",
    "    \n",
    "    summary_data = [\n",
    "        [\"Model Name\", model_name],\n",
    "        [\"Model Type\", model_type],\n",
    "        [\"Epsilon\", str(epsilon)],\n",
    "        [\"Gamma\", str(gamma)],\n",
    "        [\"Learning Rate\", str(learning_rate)],\n",
    "        [\"Replay Memory Size\", str(replay_memory_size)],\n",
    "        [\"Epochs\", str(epochs)],\n",
    "        [\"Target NN Update Frequency\", str(freq_of_target_nn_update)],\n",
    "        [\"Final Loss\", str(loss_value)],\n",
    "        [\"Final Evaluation Steps\", str(steps) if 'steps' in locals() else 'N/A'],\n",
    "        [\"Final Evaluation Score\", str(score) if 'score' in locals() else 'N/A']\n",
    "    ]\n",
    "    \n",
    "    summary_table = wandb.Table(columns=[\"Parameter\", \"Value\"], data=summary_data)\n",
    "    wandb.log({\"training_summary_table\": summary_table})\n",
    "    \n",
    "    if save_model:\n",
    "        active_nn.save(f\"{model_name}.pth\")\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    return active_nn, target_nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082bf4bd",
   "metadata": {},
   "source": [
    "### Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0a02525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [initial_state, action, final_state, dead, reward]\n",
    "state_action_pairs = deque(maxlen=REPLAY_MEMORY_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2403929",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 16\n",
    "active_nn = DQN_scaled_ff(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE).to(device=device)\n",
    "\n",
    "game = Snake()\n",
    "for episode in range(REPLAY_MEMORY_SIZE):\n",
    "    initial_state = game.get_state()\n",
    "    action_pred = torch.argmax(active_nn(torch.tensor(initial_state, dtype=torch.float32).to(device)))\n",
    "    action = policy(EPSILON, ACTION_SPACE, action_pred)\n",
    "    done = game.move_with_action(action=action)\n",
    "    final_state = game.get_state()\n",
    "    reward = game.get_immediate_reward()\n",
    "    \n",
    "    state_action_pairs.append((initial_state, action, reward, final_state, done))\n",
    "    EPSILON *= EPSILON_DECAY\n",
    "\n",
    "    if done == 1:\n",
    "        game = Snake()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "549d9223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ayushdeolasee/Developer/ml_snake_game/wandb/run-20250610_192233-igo6zi8f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pypdeveloper/snake_game_rl/runs/igo6zi8f' target=\"_blank\">initial_base_model_run</a></strong> to <a href='https://wandb.ai/pypdeveloper/snake_game_rl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pypdeveloper/snake_game_rl' target=\"_blank\">https://wandb.ai/pypdeveloper/snake_game_rl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pypdeveloper/snake_game_rl/runs/igo6zi8f' target=\"_blank\">https://wandb.ai/pypdeveloper/snake_game_rl/runs/igo6zi8f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.29449227452278137\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 1\n",
      "Epoch 1, Loss: 0.00926232896745205\n",
      "Epoch 2, Loss: 0.012865720316767693\n",
      "Epoch 3, Loss: 9.183608926832676e-05\n",
      "Epoch 4, Loss: 0.1681126058101654\n",
      "Epoch 5, Loss: 0.017012910917401314\n",
      "Epoch 6, Loss: 1.627926576475147e-05\n",
      "Epoch 7, Loss: 0.0009350040927529335\n",
      "Epoch 8, Loss: 13.79163646697998\n",
      "Epoch 9, Loss: 0.008541463874280453\n",
      "Epoch 10, Loss: 0.016976360231637955\n",
      "Epoch 11, Loss: 0.04102009907364845\n",
      "Epoch 12, Loss: 0.006098002661019564\n",
      "Epoch 13, Loss: 0.0025676083751022816\n",
      "Epoch 14, Loss: 0.00011074024223489687\n",
      "Epoch 15, Loss: 0.04613468423485756\n",
      "Epoch 16, Loss: 0.0014864255208522081\n",
      "Epoch 17, Loss: 0.002015576232224703\n",
      "Epoch 18, Loss: 0.0122377909719944\n",
      "Epoch 19, Loss: 0.20847086608409882\n",
      "Epoch 20, Loss: 0.0025835803244262934\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 21, Loss: 0.04392904415726662\n",
      "Epoch 22, Loss: 0.027787817642092705\n",
      "Epoch 23, Loss: 0.019414285197854042\n",
      "Epoch 24, Loss: 0.0021136400755494833\n",
      "Epoch 25, Loss: 0.014965023845434189\n",
      "Epoch 26, Loss: 0.0028135981410741806\n",
      "Epoch 27, Loss: 0.0262981578707695\n",
      "Epoch 28, Loss: 0.007778485305607319\n",
      "Epoch 29, Loss: 0.0007916755275800824\n",
      "Epoch 30, Loss: 0.24917954206466675\n",
      "Epoch 31, Loss: 0.026779381558299065\n",
      "Epoch 32, Loss: 0.021922845393419266\n",
      "Epoch 33, Loss: 0.008381858468055725\n",
      "Epoch 34, Loss: 0.0016706621972844005\n",
      "Epoch 35, Loss: 0.0029992295894771814\n",
      "Epoch 36, Loss: 0.009026635438203812\n",
      "Epoch 37, Loss: 0.029955681413412094\n",
      "Epoch 38, Loss: 0.0023901788517832756\n",
      "Epoch 39, Loss: 0.0033719174098223448\n",
      "Epoch 40, Loss: 0.00544022535905242\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 16, Score: 0\n",
      "Epoch 41, Loss: 0.04194621369242668\n",
      "Epoch 42, Loss: 0.016677111387252808\n",
      "Epoch 43, Loss: 0.00928037241101265\n",
      "Epoch 44, Loss: 0.04021000117063522\n",
      "Epoch 45, Loss: 0.275020569562912\n",
      "Epoch 46, Loss: 0.01998043619096279\n",
      "Epoch 47, Loss: 0.02884136512875557\n",
      "Epoch 48, Loss: 0.022777680307626724\n",
      "Epoch 49, Loss: 0.0003472289245110005\n",
      "Epoch 50, Loss: 0.009734169580042362\n",
      "Epoch 51, Loss: 0.050660040229558945\n",
      "Epoch 52, Loss: 0.0016056474996730685\n",
      "Epoch 53, Loss: 0.1998055875301361\n",
      "Epoch 54, Loss: 18.06429100036621\n",
      "Epoch 55, Loss: 0.17879556119441986\n",
      "Epoch 56, Loss: 0.13666288554668427\n",
      "Epoch 57, Loss: 0.18406012654304504\n",
      "Epoch 58, Loss: 0.012342603877186775\n",
      "Epoch 59, Loss: 0.017727462574839592\n",
      "Epoch 60, Loss: 0.001322935800999403\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 61, Loss: 0.03407924622297287\n",
      "Epoch 62, Loss: 0.033713314682245255\n",
      "Epoch 63, Loss: 0.029970210045576096\n",
      "Epoch 64, Loss: 0.0018267674604430795\n",
      "Epoch 65, Loss: 0.03961323946714401\n",
      "Epoch 66, Loss: 0.061278875917196274\n",
      "Epoch 67, Loss: 0.03957343474030495\n",
      "Epoch 68, Loss: 0.07412248849868774\n",
      "Epoch 69, Loss: 0.009197117760777473\n",
      "Epoch 70, Loss: 0.009308747947216034\n",
      "Epoch 71, Loss: 0.20232602953910828\n",
      "Epoch 72, Loss: 0.011211284436285496\n",
      "Epoch 73, Loss: 0.025158260017633438\n",
      "Epoch 74, Loss: 0.018811214715242386\n",
      "Epoch 75, Loss: 0.018183931708335876\n",
      "Epoch 76, Loss: 0.024964220821857452\n",
      "Epoch 77, Loss: 0.019323689863085747\n",
      "Epoch 78, Loss: 0.024758439511060715\n",
      "Epoch 79, Loss: 0.012456377036869526\n",
      "Epoch 80, Loss: 0.047365833073854446\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 24, Score: 0\n",
      "Epoch 81, Loss: 0.012788654305040836\n",
      "Epoch 82, Loss: 29.62856674194336\n",
      "Epoch 83, Loss: 0.0017240389715880156\n",
      "Epoch 84, Loss: 0.0030047879554331303\n",
      "Epoch 85, Loss: 0.0040037077851593494\n",
      "Epoch 86, Loss: 0.005301043391227722\n",
      "Epoch 87, Loss: 0.011399318464100361\n",
      "Epoch 88, Loss: 0.005220149178057909\n",
      "Epoch 89, Loss: 0.18156273663043976\n",
      "Epoch 90, Loss: 0.8482003211975098\n",
      "Epoch 91, Loss: 0.3925970792770386\n",
      "Epoch 92, Loss: 16.062198638916016\n",
      "Epoch 93, Loss: 0.21596920490264893\n",
      "Epoch 94, Loss: 0.009199198335409164\n",
      "Epoch 95, Loss: 0.0011538687394931912\n",
      "Epoch 96, Loss: 0.471174955368042\n",
      "Epoch 97, Loss: 1.3210879564285278\n",
      "Epoch 98, Loss: 0.09936938434839249\n",
      "Epoch 99, Loss: 0.9522936344146729\n",
      "Epoch 100, Loss: 0.9993839859962463\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 16, Score: 0\n",
      "Epoch 101, Loss: 0.006027089431881905\n",
      "Epoch 102, Loss: 0.020092276856303215\n",
      "Epoch 103, Loss: 0.003951845690608025\n",
      "Epoch 104, Loss: 0.011185556650161743\n",
      "Epoch 105, Loss: 0.0181889645755291\n",
      "Epoch 106, Loss: 1.1607658052525949e-05\n",
      "Epoch 107, Loss: 0.006453581154346466\n",
      "Epoch 108, Loss: 0.012753789313137531\n",
      "Epoch 109, Loss: 0.07455506920814514\n",
      "Epoch 110, Loss: 0.003145873546600342\n",
      "Epoch 111, Loss: 0.0007047407561913133\n",
      "Epoch 112, Loss: 0.010086233727633953\n",
      "Epoch 113, Loss: 0.007320241536945105\n",
      "Epoch 114, Loss: 0.0018048129277303815\n",
      "Epoch 115, Loss: 0.2825016975402832\n",
      "Epoch 116, Loss: 0.02283482253551483\n",
      "Epoch 117, Loss: 0.03059099055826664\n",
      "Epoch 118, Loss: 0.00042697033495642245\n",
      "Epoch 119, Loss: 0.00045338860945776105\n",
      "Epoch 120, Loss: 0.008748606778681278\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 1\n",
      "Epoch 121, Loss: 0.2199254035949707\n",
      "Epoch 122, Loss: 0.04143467918038368\n",
      "Epoch 123, Loss: 0.0008774956804700196\n",
      "Epoch 124, Loss: 0.024988166987895966\n",
      "Epoch 125, Loss: 0.016565104946494102\n",
      "Epoch 126, Loss: 0.015104059129953384\n",
      "Epoch 127, Loss: 0.015396363101899624\n",
      "Epoch 128, Loss: 0.015123873949050903\n",
      "Epoch 129, Loss: 0.002373464172706008\n",
      "Epoch 130, Loss: 0.048127539455890656\n",
      "Epoch 131, Loss: 0.12369655817747116\n",
      "Epoch 132, Loss: 0.12037763744592667\n",
      "Epoch 133, Loss: 0.04909972473978996\n",
      "Epoch 134, Loss: 0.017604153603315353\n",
      "Epoch 135, Loss: 4.471562385559082\n",
      "Epoch 136, Loss: 0.00943038146942854\n",
      "Epoch 137, Loss: 0.002868745708838105\n",
      "Epoch 138, Loss: 0.029186556115746498\n",
      "Epoch 139, Loss: 0.00010460055636940524\n",
      "Epoch 140, Loss: 1.1226623428228777e-05\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 18, Score: 0\n",
      "Epoch 141, Loss: 15.877178192138672\n",
      "Epoch 142, Loss: 0.019809601828455925\n",
      "Epoch 143, Loss: 0.0007901987410150468\n",
      "Epoch 144, Loss: 2.2082762370700948e-05\n",
      "Epoch 145, Loss: 0.005368050187826157\n",
      "Epoch 146, Loss: 0.001654910040087998\n",
      "Epoch 147, Loss: 0.15502455830574036\n",
      "Epoch 148, Loss: 0.22259147465229034\n",
      "Epoch 149, Loss: 0.2317933589220047\n",
      "Epoch 150, Loss: 0.2596874535083771\n",
      "Epoch 151, Loss: 0.5061198472976685\n",
      "Epoch 152, Loss: 0.05293367803096771\n",
      "Epoch 153, Loss: 0.1553436517715454\n",
      "Epoch 154, Loss: 0.16748790442943573\n",
      "Epoch 155, Loss: 0.04916682839393616\n",
      "Epoch 156, Loss: 7.326035847654566e-05\n",
      "Epoch 157, Loss: 0.015180632472038269\n",
      "Epoch 158, Loss: 0.00802920013666153\n",
      "Epoch 159, Loss: 0.09803897887468338\n",
      "Epoch 160, Loss: 0.014776986092329025\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 16, Score: 0\n",
      "Epoch 161, Loss: 0.0007604373386129737\n",
      "Epoch 162, Loss: 0.004505968187004328\n",
      "Epoch 163, Loss: 0.0013654130743816495\n",
      "Epoch 164, Loss: 0.005542094353586435\n",
      "Epoch 165, Loss: 0.07864509522914886\n",
      "Epoch 166, Loss: 0.016979467123746872\n",
      "Epoch 167, Loss: 0.019347501918673515\n",
      "Epoch 168, Loss: 0.001271237968467176\n",
      "Epoch 169, Loss: 0.007507790345698595\n",
      "Epoch 170, Loss: 11.754339218139648\n",
      "Epoch 171, Loss: 0.035624951124191284\n",
      "Epoch 172, Loss: 0.026654774323105812\n",
      "Epoch 173, Loss: 0.02556181699037552\n",
      "Epoch 174, Loss: 0.029983583837747574\n",
      "Epoch 175, Loss: 0.022048059850931168\n",
      "Epoch 176, Loss: 0.05285833403468132\n",
      "Epoch 177, Loss: 0.13473519682884216\n",
      "Epoch 178, Loss: 0.0010436285519972444\n",
      "Epoch 179, Loss: 0.015251509845256805\n",
      "Epoch 180, Loss: 9.5822114944458\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 16, Score: 0\n",
      "Epoch 181, Loss: 3.270361776230857e-05\n",
      "Epoch 182, Loss: 0.1783967763185501\n",
      "Epoch 183, Loss: 0.012901628389954567\n",
      "Epoch 184, Loss: 0.14257559180259705\n",
      "Epoch 185, Loss: 0.047745320945978165\n",
      "Epoch 186, Loss: 0.00042867043521255255\n",
      "Epoch 187, Loss: 0.0715297982096672\n",
      "Epoch 188, Loss: 0.07908914983272552\n",
      "Epoch 189, Loss: 0.01293222326785326\n",
      "Epoch 190, Loss: 0.017754701897501945\n",
      "Epoch 191, Loss: 0.48169055581092834\n",
      "Epoch 192, Loss: 0.355410635471344\n",
      "Epoch 193, Loss: 7.569845199584961\n",
      "Epoch 194, Loss: 0.062242291867733\n",
      "Epoch 195, Loss: 0.037384986877441406\n",
      "Epoch 196, Loss: 0.1586994230747223\n",
      "Epoch 197, Loss: 0.0001757930003805086\n",
      "Epoch 198, Loss: 0.057476840913295746\n",
      "Epoch 199, Loss: 0.11040312051773071\n",
      "Epoch 200, Loss: 0.019322438165545464\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 16, Score: 0\n",
      "Epoch 201, Loss: 0.002797371009364724\n",
      "Epoch 202, Loss: 0.003505774773657322\n",
      "Epoch 203, Loss: 0.012346537783741951\n",
      "Epoch 204, Loss: 0.002297673374414444\n",
      "Epoch 205, Loss: 0.0008355353493243456\n",
      "Epoch 206, Loss: 0.032056666910648346\n",
      "Epoch 207, Loss: 0.005659965332597494\n",
      "Epoch 208, Loss: 0.025817157700657845\n",
      "Epoch 209, Loss: 0.02508815936744213\n",
      "Epoch 210, Loss: 0.0057113091461360455\n",
      "Epoch 211, Loss: 0.007844981737434864\n",
      "Epoch 212, Loss: 0.020616915076971054\n",
      "Epoch 213, Loss: 0.003701880108565092\n",
      "Epoch 214, Loss: 0.06085549667477608\n",
      "Epoch 215, Loss: 0.001859829993918538\n",
      "Epoch 216, Loss: 0.0008262438932433724\n",
      "Epoch 217, Loss: 0.0010717628756538033\n",
      "Epoch 218, Loss: 0.029848117381334305\n",
      "Epoch 219, Loss: 0.07419545948505402\n",
      "Epoch 220, Loss: 0.03935277462005615\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 16, Score: 0\n",
      "Epoch 221, Loss: 0.03907153382897377\n",
      "Epoch 222, Loss: 0.0009557016310282052\n",
      "Epoch 223, Loss: 0.0055733416229486465\n",
      "Epoch 224, Loss: 0.0020508808083832264\n",
      "Epoch 225, Loss: 0.04013154283165932\n",
      "Epoch 226, Loss: 0.23046906292438507\n",
      "Epoch 227, Loss: 0.029162121936678886\n",
      "Epoch 228, Loss: 0.04569614306092262\n",
      "Epoch 229, Loss: 0.030824219807982445\n",
      "Epoch 230, Loss: 0.02883310429751873\n",
      "Epoch 231, Loss: 0.022897735238075256\n",
      "Epoch 232, Loss: 0.27821967005729675\n",
      "Epoch 233, Loss: 0.08817524462938309\n",
      "Epoch 234, Loss: 0.09842590242624283\n",
      "Epoch 235, Loss: 0.01783468946814537\n",
      "Epoch 236, Loss: 3.0144734409986995e-05\n",
      "Epoch 237, Loss: 0.016892218962311745\n",
      "Epoch 238, Loss: 0.03348641097545624\n",
      "Epoch 239, Loss: 0.032367028295993805\n",
      "Epoch 240, Loss: 0.0077231265604496\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 241, Loss: 0.012071039527654648\n",
      "Epoch 242, Loss: 0.03503181040287018\n",
      "Epoch 243, Loss: 0.0062617347575724125\n",
      "Epoch 244, Loss: 0.029140792787075043\n",
      "Epoch 245, Loss: 0.13956820964813232\n",
      "Epoch 246, Loss: 0.06633248180150986\n",
      "Epoch 247, Loss: 0.006083155050873756\n",
      "Epoch 248, Loss: 0.0023703870829194784\n",
      "Epoch 249, Loss: 0.006823034957051277\n",
      "Epoch 250, Loss: 5.80347796130809e-06\n",
      "Epoch 251, Loss: 5.9392328694229946e-05\n",
      "Epoch 252, Loss: 0.0026379607152193785\n",
      "Epoch 253, Loss: 0.000345427542924881\n",
      "Epoch 254, Loss: 0.0005593248060904443\n",
      "Epoch 255, Loss: 0.053233932703733444\n",
      "Epoch 256, Loss: 0.03421976789832115\n",
      "Epoch 257, Loss: 0.0025420605670660734\n",
      "Epoch 258, Loss: 0.11282099783420563\n",
      "Epoch 259, Loss: 0.04503690078854561\n",
      "Epoch 260, Loss: 0.0018774408381432295\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 16, Score: 0\n",
      "Epoch 261, Loss: 0.01058267429471016\n",
      "Epoch 262, Loss: 0.0005204583867453039\n",
      "Epoch 263, Loss: 0.03522530198097229\n",
      "Epoch 264, Loss: 0.022815082222223282\n",
      "Epoch 265, Loss: 0.016127750277519226\n",
      "Epoch 266, Loss: 0.025185154750943184\n",
      "Epoch 267, Loss: 0.2124655544757843\n",
      "Epoch 268, Loss: 0.002833742182701826\n",
      "Epoch 269, Loss: 0.021179530769586563\n",
      "Epoch 270, Loss: 5.217531361267902e-05\n",
      "Epoch 271, Loss: 0.006306792609393597\n",
      "Epoch 272, Loss: 0.012867748737335205\n",
      "Epoch 273, Loss: 0.07447575777769089\n",
      "Epoch 274, Loss: 0.0040649776346981525\n",
      "Epoch 275, Loss: 0.0015090127708390355\n",
      "Epoch 276, Loss: 0.13952314853668213\n",
      "Epoch 277, Loss: 0.003882473800331354\n",
      "Epoch 278, Loss: 0.024855302646756172\n",
      "Epoch 279, Loss: 0.002061800565570593\n",
      "Epoch 280, Loss: 0.0011053307680413127\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 16, Score: 0\n",
      "Epoch 281, Loss: 0.07972047477960587\n",
      "Epoch 282, Loss: 0.015432358719408512\n",
      "Epoch 283, Loss: 0.004217943642288446\n",
      "Epoch 284, Loss: 0.006477180402725935\n",
      "Epoch 285, Loss: 0.0009700763039290905\n",
      "Epoch 286, Loss: 0.04835239425301552\n",
      "Epoch 287, Loss: 1.8754399206954986e-05\n",
      "Epoch 288, Loss: 0.007557017263025045\n",
      "Epoch 289, Loss: 0.3323032855987549\n",
      "Epoch 290, Loss: 15.27352523803711\n",
      "Epoch 291, Loss: 0.10519865900278091\n",
      "Epoch 292, Loss: 0.1092909649014473\n",
      "Epoch 293, Loss: 0.0059956274926662445\n",
      "Epoch 294, Loss: 0.0015815870137885213\n",
      "Epoch 295, Loss: 0.00048701342893764377\n",
      "Epoch 296, Loss: 0.002807026030495763\n",
      "Epoch 297, Loss: 0.0035116213839501143\n",
      "Epoch 298, Loss: 0.3128180205821991\n",
      "Epoch 299, Loss: 0.04864973947405815\n",
      "Epoch 300, Loss: 0.2025502473115921\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 16, Score: 0\n",
      "Epoch 301, Loss: 2.69207763671875\n",
      "Epoch 302, Loss: 0.03948631137609482\n",
      "Epoch 303, Loss: 0.026647435501217842\n",
      "Epoch 304, Loss: 0.032825153321027756\n",
      "Epoch 305, Loss: 0.02513890154659748\n",
      "Epoch 306, Loss: 0.05937064439058304\n",
      "Epoch 307, Loss: 0.07400906085968018\n",
      "Epoch 308, Loss: 0.004424526356160641\n",
      "Epoch 309, Loss: 0.1644783318042755\n",
      "Epoch 310, Loss: 5.185376721783541e-05\n",
      "Epoch 311, Loss: 0.017441431060433388\n",
      "Epoch 312, Loss: 0.08009675145149231\n",
      "Epoch 313, Loss: 0.06291002780199051\n",
      "Epoch 314, Loss: 0.006199123803526163\n",
      "Epoch 315, Loss: 1.2242043018341064\n",
      "Epoch 316, Loss: 0.008603813126683235\n",
      "Epoch 317, Loss: 0.0028183807153254747\n",
      "Epoch 318, Loss: 0.34139284491539\n",
      "Epoch 319, Loss: 0.0045166015625\n",
      "Epoch 320, Loss: 3.594312906265259\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 29, Score: 0\n",
      "Epoch 321, Loss: 0.011968620121479034\n",
      "Epoch 322, Loss: 0.0569237619638443\n",
      "Epoch 323, Loss: 0.02120528370141983\n",
      "Epoch 324, Loss: 0.08266133069992065\n",
      "Epoch 325, Loss: 0.027870384976267815\n",
      "Epoch 326, Loss: 0.0057382057420909405\n",
      "Epoch 327, Loss: 0.11067580431699753\n",
      "Epoch 328, Loss: 0.013122267089784145\n",
      "Epoch 329, Loss: 9.398072242736816\n",
      "Epoch 330, Loss: 0.0012228789273649454\n",
      "Epoch 331, Loss: 0.2887499928474426\n",
      "Epoch 332, Loss: 0.1081746369600296\n",
      "Epoch 333, Loss: 0.11782319843769073\n",
      "Epoch 334, Loss: 0.1259768158197403\n",
      "Epoch 335, Loss: 0.21283717453479767\n",
      "Epoch 336, Loss: 0.21944187581539154\n",
      "Epoch 337, Loss: 0.19653896987438202\n",
      "Epoch 338, Loss: 0.017474127933382988\n",
      "Epoch 339, Loss: 0.22864146530628204\n",
      "Epoch 340, Loss: 0.328213632106781\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 341, Loss: 1.4698710401717108e-05\n",
      "Epoch 342, Loss: 0.0037700471002608538\n",
      "Epoch 343, Loss: 0.02744545228779316\n",
      "Epoch 344, Loss: 0.013041038997471333\n",
      "Epoch 345, Loss: 0.028699742630124092\n",
      "Epoch 346, Loss: 0.0013086680555716157\n",
      "Epoch 347, Loss: 8.250258445739746\n",
      "Epoch 348, Loss: 0.03635600581765175\n",
      "Epoch 349, Loss: 0.04001708701252937\n",
      "Epoch 350, Loss: 0.004871984012424946\n",
      "Epoch 351, Loss: 0.01888921856880188\n",
      "Epoch 352, Loss: 0.0010370995150879025\n",
      "Epoch 353, Loss: 0.0033095688559114933\n",
      "Epoch 354, Loss: 0.10392367094755173\n",
      "Epoch 355, Loss: 0.0011021823156625032\n",
      "Epoch 356, Loss: 0.003750419709831476\n",
      "Epoch 357, Loss: 0.05485153570771217\n",
      "Epoch 358, Loss: 0.00012426936882548034\n",
      "Epoch 359, Loss: 0.02120712399482727\n",
      "Epoch 360, Loss: 0.006147963926196098\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 361, Loss: 0.030352385714650154\n",
      "Epoch 362, Loss: 0.03638144209980965\n",
      "Epoch 363, Loss: 0.02318739891052246\n",
      "Epoch 364, Loss: 0.17425359785556793\n",
      "Epoch 365, Loss: 0.0033345443662256002\n",
      "Epoch 366, Loss: 0.006831328384578228\n",
      "Epoch 367, Loss: 0.020240912213921547\n",
      "Epoch 368, Loss: 0.10988207906484604\n",
      "Epoch 369, Loss: 0.01110435277223587\n",
      "Epoch 370, Loss: 0.043846383690834045\n",
      "Epoch 371, Loss: 0.01231132447719574\n",
      "Epoch 372, Loss: 0.099457748234272\n",
      "Epoch 373, Loss: 0.002770494669675827\n",
      "Epoch 374, Loss: 0.005499631632119417\n",
      "Epoch 375, Loss: 0.03271889314055443\n",
      "Epoch 376, Loss: 0.05212658643722534\n",
      "Epoch 377, Loss: 4.5827268877474125e-06\n",
      "Epoch 378, Loss: 0.0041705709882080555\n",
      "Epoch 379, Loss: 0.014199770987033844\n",
      "Epoch 380, Loss: 1.8839158656192012e-05\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 35, Score: 0\n",
      "Epoch 381, Loss: 0.0001382272457703948\n",
      "Epoch 382, Loss: 0.009344805963337421\n",
      "Epoch 383, Loss: 8.463000995106995e-06\n",
      "Epoch 384, Loss: 0.009301258251070976\n",
      "Epoch 385, Loss: 0.02342800609767437\n",
      "Epoch 386, Loss: 9.222263179253787e-05\n",
      "Epoch 387, Loss: 0.00756752910092473\n",
      "Epoch 388, Loss: 0.020018570125102997\n",
      "Epoch 389, Loss: 0.003579084062948823\n",
      "Epoch 390, Loss: 0.009450123645365238\n",
      "Epoch 391, Loss: 0.005809420719742775\n",
      "Epoch 392, Loss: 0.009569879621267319\n",
      "Epoch 393, Loss: 0.0001513401948614046\n",
      "Epoch 394, Loss: 0.000567330454941839\n",
      "Epoch 395, Loss: 5.2286450227256864e-05\n",
      "Epoch 396, Loss: 0.1217394471168518\n",
      "Epoch 397, Loss: 0.01899806410074234\n",
      "Epoch 398, Loss: 0.0005959009286016226\n",
      "Epoch 399, Loss: 0.0015330209862440825\n",
      "Epoch 400, Loss: 0.3079749047756195\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 401, Loss: 0.0005791164003312588\n",
      "Epoch 402, Loss: 0.0010108628775924444\n",
      "Epoch 403, Loss: 0.014848440885543823\n",
      "Epoch 404, Loss: 0.002037741243839264\n",
      "Epoch 405, Loss: 0.0027428988832980394\n",
      "Epoch 406, Loss: 0.00017009925795719028\n",
      "Epoch 407, Loss: 0.018668292090296745\n",
      "Epoch 408, Loss: 0.007493253797292709\n",
      "Epoch 409, Loss: 0.007060875650495291\n",
      "Epoch 410, Loss: 0.03286626562476158\n",
      "Epoch 411, Loss: 0.004914604127407074\n",
      "Epoch 412, Loss: 0.036067862063646317\n",
      "Epoch 413, Loss: 0.01847212016582489\n",
      "Epoch 414, Loss: 0.014530269429087639\n",
      "Epoch 415, Loss: 0.04758976772427559\n",
      "Epoch 416, Loss: 0.0272833164781332\n",
      "Epoch 417, Loss: 0.0022160811349749565\n",
      "Epoch 418, Loss: 0.0020359596237540245\n",
      "Epoch 419, Loss: 0.019223613664507866\n",
      "Epoch 420, Loss: 0.014429598115384579\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 421, Loss: 3.2845754623413086\n",
      "Epoch 422, Loss: 0.010726197622716427\n",
      "Epoch 423, Loss: 0.004948492161929607\n",
      "Epoch 424, Loss: 0.0003981779736932367\n",
      "Epoch 425, Loss: 0.00805193092674017\n",
      "Epoch 426, Loss: 0.22786842286586761\n",
      "Epoch 427, Loss: 0.01977674849331379\n",
      "Epoch 428, Loss: 0.0054670232348144054\n",
      "Epoch 429, Loss: 0.0014640382723882794\n",
      "Epoch 430, Loss: 0.00429468834772706\n",
      "Epoch 431, Loss: 0.008290606550872326\n",
      "Epoch 432, Loss: 0.0024517830461263657\n",
      "Epoch 433, Loss: 0.004544572904706001\n",
      "Epoch 434, Loss: 0.03597426414489746\n",
      "Epoch 435, Loss: 0.308223694562912\n",
      "Epoch 436, Loss: 0.05677022412419319\n",
      "Epoch 437, Loss: 4.378857135772705\n",
      "Epoch 438, Loss: 0.028961073607206345\n",
      "Epoch 439, Loss: 0.013843215070664883\n",
      "Epoch 440, Loss: 0.0023358184844255447\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 441, Loss: 0.019880032166838646\n",
      "Epoch 442, Loss: 0.020792098715901375\n",
      "Epoch 443, Loss: 0.008005151525139809\n",
      "Epoch 444, Loss: 0.018226098269224167\n",
      "Epoch 445, Loss: 0.00022712528880219907\n",
      "Epoch 446, Loss: 0.016471154987812042\n",
      "Epoch 447, Loss: 0.030742336064577103\n",
      "Epoch 448, Loss: 0.0632016509771347\n",
      "Epoch 449, Loss: 0.012029517441987991\n",
      "Epoch 450, Loss: 0.1273011714220047\n",
      "Epoch 451, Loss: 0.022963514551520348\n",
      "Epoch 452, Loss: 0.1732684075832367\n",
      "Epoch 453, Loss: 0.002723155776038766\n",
      "Epoch 454, Loss: 0.04506039246916771\n",
      "Epoch 455, Loss: 0.08204595744609833\n",
      "Epoch 456, Loss: 0.014235933311283588\n",
      "Epoch 457, Loss: 0.029907215386629105\n",
      "Epoch 458, Loss: 0.1208043098449707\n",
      "Epoch 459, Loss: 0.01913183368742466\n",
      "Epoch 460, Loss: 0.00011641933815553784\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 461, Loss: 0.0013749300269410014\n",
      "Epoch 462, Loss: 0.0005075453082099557\n",
      "Epoch 463, Loss: 0.001823696424253285\n",
      "Epoch 464, Loss: 1.092422604560852\n",
      "Epoch 465, Loss: 0.0011883507249876857\n",
      "Epoch 466, Loss: 0.04802512750029564\n",
      "Epoch 467, Loss: 0.017446577548980713\n",
      "Epoch 468, Loss: 0.012483666650950909\n",
      "Epoch 469, Loss: 0.022969810292124748\n",
      "Epoch 470, Loss: 0.014819635078310966\n",
      "Epoch 471, Loss: 3.6954457759857178\n",
      "Epoch 472, Loss: 0.052768148481845856\n",
      "Epoch 473, Loss: 0.07850416004657745\n",
      "Epoch 474, Loss: 0.000909248657990247\n",
      "Epoch 475, Loss: 0.0038174428045749664\n",
      "Epoch 476, Loss: 0.03289015218615532\n",
      "Epoch 477, Loss: 0.0641961395740509\n",
      "Epoch 478, Loss: 0.00030985125340521336\n",
      "Epoch 479, Loss: 0.0033518243581056595\n",
      "Epoch 480, Loss: 0.00026533330674283206\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 32, Score: 0\n",
      "Epoch 481, Loss: 0.00037446137866936624\n",
      "Epoch 482, Loss: 0.012505213730037212\n",
      "Epoch 483, Loss: 0.04280494153499603\n",
      "Epoch 484, Loss: 0.02474328689277172\n",
      "Epoch 485, Loss: 0.0198680330067873\n",
      "Epoch 486, Loss: 1.5409451723098755\n",
      "Epoch 487, Loss: 0.04450251907110214\n",
      "Epoch 488, Loss: 0.007341093849390745\n",
      "Epoch 489, Loss: 0.03395785391330719\n",
      "Epoch 490, Loss: 0.004318501800298691\n",
      "Epoch 491, Loss: 0.08905798196792603\n",
      "Epoch 492, Loss: 0.02202554978430271\n",
      "Epoch 493, Loss: 0.0060382746160030365\n",
      "Epoch 494, Loss: 0.003951335791498423\n",
      "Epoch 495, Loss: 9.135579109191895\n",
      "Epoch 496, Loss: 0.31716129183769226\n",
      "Epoch 497, Loss: 0.0014456573408097029\n",
      "Epoch 498, Loss: 0.0021434850059449673\n",
      "Epoch 499, Loss: 3.6659018993377686\n",
      "Epoch 500, Loss: 0.00014347319665830582\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 23, Score: 0\n",
      "Epoch 501, Loss: 0.028585510328412056\n",
      "Epoch 502, Loss: 2.360743522644043\n",
      "Epoch 503, Loss: 0.025604145601391792\n",
      "Epoch 504, Loss: 0.046117786318063736\n",
      "Epoch 505, Loss: 3.214780569076538\n",
      "Epoch 506, Loss: 0.000902732543181628\n",
      "Epoch 507, Loss: 0.23931439220905304\n",
      "Epoch 508, Loss: 2.4166722297668457\n",
      "Epoch 509, Loss: 0.0016197891673073173\n",
      "Epoch 510, Loss: 0.057483699172735214\n",
      "Epoch 511, Loss: 0.013659671880304813\n",
      "Epoch 512, Loss: 0.0008425191044807434\n",
      "Epoch 513, Loss: 0.0969381332397461\n",
      "Epoch 514, Loss: 0.09510748833417892\n",
      "Epoch 515, Loss: 0.5885434746742249\n",
      "Epoch 516, Loss: 0.7603893280029297\n",
      "Epoch 517, Loss: 0.0380035862326622\n",
      "Epoch 518, Loss: 0.6458173990249634\n",
      "Epoch 519, Loss: 0.0007452020654454827\n",
      "Epoch 520, Loss: 0.24170109629631042\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 54, Score: 0\n",
      "Epoch 521, Loss: 0.006147228647023439\n",
      "Epoch 522, Loss: 0.018405750393867493\n",
      "Epoch 523, Loss: 0.009226704947650433\n",
      "Epoch 524, Loss: 0.0018169167451560497\n",
      "Epoch 525, Loss: 2.092289924621582\n",
      "Epoch 526, Loss: 0.0023969383910298347\n",
      "Epoch 527, Loss: 0.00023031271120999008\n",
      "Epoch 528, Loss: 0.022755160927772522\n",
      "Epoch 529, Loss: 0.0216293353587389\n",
      "Epoch 530, Loss: 0.004232480190694332\n",
      "Epoch 531, Loss: 0.0007174881175160408\n",
      "Epoch 532, Loss: 0.06643956154584885\n",
      "Epoch 533, Loss: 0.00859797652810812\n",
      "Epoch 534, Loss: 0.08165515214204788\n",
      "Epoch 535, Loss: 0.0038060201331973076\n",
      "Epoch 536, Loss: 0.10024205595254898\n",
      "Epoch 537, Loss: 0.0029963315464556217\n",
      "Epoch 538, Loss: 0.04908498004078865\n",
      "Epoch 539, Loss: 0.055356524884700775\n",
      "Epoch 540, Loss: 0.009428892284631729\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 541, Loss: 0.014194543473422527\n",
      "Epoch 542, Loss: 0.00015477351553272456\n",
      "Epoch 543, Loss: 0.014909528195858002\n",
      "Epoch 544, Loss: 0.03501727059483528\n",
      "Epoch 545, Loss: 0.0005828000139445066\n",
      "Epoch 546, Loss: 0.0001107854041038081\n",
      "Epoch 547, Loss: 0.0991913229227066\n",
      "Epoch 548, Loss: 0.010060079395771027\n",
      "Epoch 549, Loss: 0.00011655190610326827\n",
      "Epoch 550, Loss: 0.0015794257633388042\n",
      "Epoch 551, Loss: 0.00015401214477606118\n",
      "Epoch 552, Loss: 0.00042611846583895385\n",
      "Epoch 553, Loss: 0.0052370959892869\n",
      "Epoch 554, Loss: 0.0023964308202266693\n",
      "Epoch 555, Loss: 1.0900711231442983e-06\n",
      "Epoch 556, Loss: 4.129766464233398\n",
      "Epoch 557, Loss: 0.0006685382686555386\n",
      "Epoch 558, Loss: 1.9167324353475124e-05\n",
      "Epoch 559, Loss: 0.0007617232040502131\n",
      "Epoch 560, Loss: 0.03192630410194397\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 60, Score: 0\n",
      "Epoch 561, Loss: 0.006589820608496666\n",
      "Epoch 562, Loss: 0.5568135976791382\n",
      "Epoch 563, Loss: 0.0018353271298110485\n",
      "Epoch 564, Loss: 0.009431445971131325\n",
      "Epoch 565, Loss: 0.07055191695690155\n",
      "Epoch 566, Loss: 0.022791249677538872\n",
      "Epoch 567, Loss: 0.03688022494316101\n",
      "Epoch 568, Loss: 0.0004020809137728065\n",
      "Epoch 569, Loss: 0.23405767977237701\n",
      "Epoch 570, Loss: 0.02471853978931904\n",
      "Epoch 571, Loss: 0.012270543724298477\n",
      "Epoch 572, Loss: 0.008922355249524117\n",
      "Epoch 573, Loss: 0.06926167756319046\n",
      "Epoch 574, Loss: 0.0032265251502394676\n",
      "Epoch 575, Loss: 0.0004265861352905631\n",
      "Epoch 576, Loss: 0.001986915012821555\n",
      "Epoch 577, Loss: 0.009656230919063091\n",
      "Epoch 578, Loss: 4.222218194627203e-05\n",
      "Epoch 579, Loss: 0.005633754190057516\n",
      "Epoch 580, Loss: 0.02637755498290062\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 581, Loss: 0.004803120624274015\n",
      "Epoch 582, Loss: 0.0002741236239671707\n",
      "Epoch 583, Loss: 0.009975914843380451\n",
      "Epoch 584, Loss: 0.0004989197477698326\n",
      "Epoch 585, Loss: 0.013422899879515171\n",
      "Epoch 586, Loss: 0.027550341561436653\n",
      "Epoch 587, Loss: 2.672383914159582e-07\n",
      "Epoch 588, Loss: 0.003909364342689514\n",
      "Epoch 589, Loss: 0.01001407578587532\n",
      "Epoch 590, Loss: 0.0033194376155734062\n",
      "Epoch 591, Loss: 0.0009773727506399155\n",
      "Epoch 592, Loss: 0.0008661126485094428\n",
      "Epoch 593, Loss: 0.0003726757422555238\n",
      "Epoch 594, Loss: 0.006668574642390013\n",
      "Epoch 595, Loss: 0.013596123084425926\n",
      "Epoch 596, Loss: 0.09545466303825378\n",
      "Epoch 597, Loss: 0.0043577756732702255\n",
      "Epoch 598, Loss: 0.008155913092195988\n",
      "Epoch 599, Loss: 0.09848380833864212\n",
      "Epoch 600, Loss: 0.04151714965701103\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 601, Loss: 0.005109003279358149\n",
      "Epoch 602, Loss: 0.0006719222292304039\n",
      "Epoch 603, Loss: 0.02740040048956871\n",
      "Epoch 604, Loss: 0.01453710999339819\n",
      "Epoch 605, Loss: 0.004528674762696028\n",
      "Epoch 606, Loss: 0.1113714724779129\n",
      "Epoch 607, Loss: 0.01655939407646656\n",
      "Epoch 608, Loss: 0.01135564036667347\n",
      "Epoch 609, Loss: 0.015410692431032658\n",
      "Epoch 610, Loss: 0.0009399133268743753\n",
      "Epoch 611, Loss: 0.0007302853045985103\n",
      "Epoch 612, Loss: 0.06264109909534454\n",
      "Epoch 613, Loss: 0.0007617922965437174\n",
      "Epoch 614, Loss: 0.011413438245654106\n",
      "Epoch 615, Loss: 0.03946693241596222\n",
      "Epoch 616, Loss: 0.0010754031827673316\n",
      "Epoch 617, Loss: 0.004500864539295435\n",
      "Epoch 618, Loss: 0.008395485579967499\n",
      "Epoch 619, Loss: 0.0001688964694039896\n",
      "Epoch 620, Loss: 0.0006503015756607056\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 621, Loss: 0.010645934380590916\n",
      "Epoch 622, Loss: 0.009832211770117283\n",
      "Epoch 623, Loss: 0.11523430049419403\n",
      "Epoch 624, Loss: 0.0006312167388387024\n",
      "Epoch 625, Loss: 0.11545195430517197\n",
      "Epoch 626, Loss: 0.007561204489320517\n",
      "Epoch 627, Loss: 0.017490362748503685\n",
      "Epoch 628, Loss: 9.593871072866023e-05\n",
      "Epoch 629, Loss: 0.0005382968811318278\n",
      "Epoch 630, Loss: 0.0064598266035318375\n",
      "Epoch 631, Loss: 0.00015497229469474405\n",
      "Epoch 632, Loss: 0.00014532396744471043\n",
      "Epoch 633, Loss: 1.3536918253009844e-08\n",
      "Epoch 634, Loss: 0.00015665675164200366\n",
      "Epoch 635, Loss: 0.002498183399438858\n",
      "Epoch 636, Loss: 0.0003315582580398768\n",
      "Epoch 637, Loss: 0.00211034482344985\n",
      "Epoch 638, Loss: 0.007242120336741209\n",
      "Epoch 639, Loss: 0.0017679319716989994\n",
      "Epoch 640, Loss: 0.02437347173690796\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 33, Score: 0\n",
      "Epoch 641, Loss: 0.0716976597905159\n",
      "Epoch 642, Loss: 0.0011224705958738923\n",
      "Epoch 643, Loss: 0.0014944057911634445\n",
      "Epoch 644, Loss: 0.01820002682507038\n",
      "Epoch 645, Loss: 0.006852809805423021\n",
      "Epoch 646, Loss: 0.0035031705629080534\n",
      "Epoch 647, Loss: 0.009821658954024315\n",
      "Epoch 648, Loss: 0.011211360804736614\n",
      "Epoch 649, Loss: 0.014840308576822281\n",
      "Epoch 650, Loss: 0.00714110815897584\n",
      "Epoch 651, Loss: 0.04633821174502373\n",
      "Epoch 652, Loss: 0.0001469263806939125\n",
      "Epoch 653, Loss: 0.004224092699587345\n",
      "Epoch 654, Loss: 0.034405261278152466\n",
      "Epoch 655, Loss: 0.01194443367421627\n",
      "Epoch 656, Loss: 0.004343661945313215\n",
      "Epoch 657, Loss: 0.028567655012011528\n",
      "Epoch 658, Loss: 0.0034507259260863066\n",
      "Epoch 659, Loss: 3.768171548843384\n",
      "Epoch 660, Loss: 0.00509893661364913\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 25, Score: 0\n",
      "Epoch 661, Loss: 0.007435372099280357\n",
      "Epoch 662, Loss: 8.567473560106009e-05\n",
      "Epoch 663, Loss: 0.00021961057791486382\n",
      "Epoch 664, Loss: 0.011875612661242485\n",
      "Epoch 665, Loss: 0.002720419317483902\n",
      "Epoch 666, Loss: 0.053538061678409576\n",
      "Epoch 667, Loss: 0.021372469142079353\n",
      "Epoch 668, Loss: 7.577944052172825e-05\n",
      "Epoch 669, Loss: 0.1090201884508133\n",
      "Epoch 670, Loss: 0.0023568933829665184\n",
      "Epoch 671, Loss: 0.011721137911081314\n",
      "Epoch 672, Loss: 0.03484677895903587\n",
      "Epoch 673, Loss: 0.00023020598746370524\n",
      "Epoch 674, Loss: 0.03732964023947716\n",
      "Epoch 675, Loss: 0.08821992576122284\n",
      "Epoch 676, Loss: 0.03496013954281807\n",
      "Epoch 677, Loss: 0.010751225054264069\n",
      "Epoch 678, Loss: 2.339287042617798\n",
      "Epoch 679, Loss: 0.007494740188121796\n",
      "Epoch 680, Loss: 0.0010580387897789478\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 681, Loss: 1.665094714553561e-05\n",
      "Epoch 682, Loss: 0.006542082875967026\n",
      "Epoch 683, Loss: 0.01620887592434883\n",
      "Epoch 684, Loss: 0.00382973812520504\n",
      "Epoch 685, Loss: 0.04591803997755051\n",
      "Epoch 686, Loss: 0.028093405067920685\n",
      "Epoch 687, Loss: 0.010038592852652073\n",
      "Epoch 688, Loss: 0.0555119588971138\n",
      "Epoch 689, Loss: 0.006880384869873524\n",
      "Epoch 690, Loss: 0.006733194459229708\n",
      "Epoch 691, Loss: 0.02126857452094555\n",
      "Epoch 692, Loss: 0.023714248090982437\n",
      "Epoch 693, Loss: 0.0027168639935553074\n",
      "Epoch 694, Loss: 4.0941549173112435e-07\n",
      "Epoch 695, Loss: 0.0017565797315910459\n",
      "Epoch 696, Loss: 0.023380188271403313\n",
      "Epoch 697, Loss: 0.06619053333997726\n",
      "Epoch 698, Loss: 0.00487892609089613\n",
      "Epoch 699, Loss: 0.01806650124490261\n",
      "Epoch 700, Loss: 0.0030850451439619064\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 19, Score: 0\n",
      "Epoch 701, Loss: 0.0002162002638215199\n",
      "Epoch 702, Loss: 0.015608812682330608\n",
      "Epoch 703, Loss: 0.0006990496185608208\n",
      "Epoch 704, Loss: 0.004600516054779291\n",
      "Epoch 705, Loss: 0.007899940945208073\n",
      "Epoch 706, Loss: 0.0036612716503441334\n",
      "Epoch 707, Loss: 0.010990608483552933\n",
      "Epoch 708, Loss: 0.0031621353700757027\n",
      "Epoch 709, Loss: 0.11928033828735352\n",
      "Epoch 710, Loss: 0.00012202841753605753\n",
      "Epoch 711, Loss: 0.003424836555495858\n",
      "Epoch 712, Loss: 0.0021617813035845757\n",
      "Epoch 713, Loss: 0.009897367097437382\n",
      "Epoch 714, Loss: 0.012819032184779644\n",
      "Epoch 715, Loss: 0.013400341384112835\n",
      "Epoch 716, Loss: 1.866334059741348e-06\n",
      "Epoch 717, Loss: 0.0009095793357118964\n",
      "Epoch 718, Loss: 6.1233680753503e-05\n",
      "Epoch 719, Loss: 0.001251934445463121\n",
      "Epoch 720, Loss: 0.02862623892724514\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 27, Score: 0\n",
      "Epoch 721, Loss: 1.774910569190979\n",
      "Epoch 722, Loss: 0.2218581736087799\n",
      "Epoch 723, Loss: 0.06396991014480591\n",
      "Epoch 724, Loss: 0.004953944124281406\n",
      "Epoch 725, Loss: 0.041861098259687424\n",
      "Epoch 726, Loss: 0.0005102345021441579\n",
      "Epoch 727, Loss: 0.013494253158569336\n",
      "Epoch 728, Loss: 0.09707756340503693\n",
      "Epoch 729, Loss: 0.5135407447814941\n",
      "Epoch 730, Loss: 0.0004333535034675151\n",
      "Epoch 731, Loss: 0.017244376242160797\n",
      "Epoch 732, Loss: 0.12778323888778687\n",
      "Epoch 733, Loss: 0.029254332184791565\n",
      "Epoch 734, Loss: 0.38409432768821716\n",
      "Epoch 735, Loss: 7.085408287821338e-05\n",
      "Epoch 736, Loss: 0.018518907949328423\n",
      "Epoch 737, Loss: 0.002125045284628868\n",
      "Epoch 738, Loss: 0.002351301722228527\n",
      "Epoch 739, Loss: 0.03799154981970787\n",
      "Epoch 740, Loss: 0.0780232846736908\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 33, Score: 0\n",
      "Epoch 741, Loss: 5.054794982584099e-08\n",
      "Epoch 742, Loss: 0.0015879841521382332\n",
      "Epoch 743, Loss: 0.09684069454669952\n",
      "Epoch 744, Loss: 0.009516380727291107\n",
      "Epoch 745, Loss: 0.0001888679398689419\n",
      "Epoch 746, Loss: 0.00010758667485788465\n",
      "Epoch 747, Loss: 0.01692892611026764\n",
      "Epoch 748, Loss: 0.005149608477950096\n",
      "Epoch 749, Loss: 3.860962897306308e-05\n",
      "Epoch 750, Loss: 0.001672170590609312\n",
      "Epoch 751, Loss: 3.0368992156581953e-05\n",
      "Epoch 752, Loss: 0.000412473629694432\n",
      "Epoch 753, Loss: 0.10987547785043716\n",
      "Epoch 754, Loss: 0.0010070166317746043\n",
      "Epoch 755, Loss: 0.00013828628289047629\n",
      "Epoch 756, Loss: 0.0010241548297926784\n",
      "Epoch 757, Loss: 3.9450902938842773\n",
      "Epoch 758, Loss: 4.295950889587402\n",
      "Epoch 759, Loss: 0.01900726929306984\n",
      "Epoch 760, Loss: 0.0015310426242649555\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 18, Score: 0\n",
      "Epoch 761, Loss: 0.011702843941748142\n",
      "Epoch 762, Loss: 0.007135588675737381\n",
      "Epoch 763, Loss: 0.0014915590872988105\n",
      "Epoch 764, Loss: 0.02037644386291504\n",
      "Epoch 765, Loss: 0.007789815776050091\n",
      "Epoch 766, Loss: 0.0005209480877965689\n",
      "Epoch 767, Loss: 0.003479911480098963\n",
      "Epoch 768, Loss: 0.0010379673913121223\n",
      "Epoch 769, Loss: 0.003208703827112913\n",
      "Epoch 770, Loss: 0.007330138236284256\n",
      "Epoch 771, Loss: 0.0006554836290888488\n",
      "Epoch 772, Loss: 0.039648789912462234\n",
      "Epoch 773, Loss: 0.04334486648440361\n",
      "Epoch 774, Loss: 0.00011938546231249347\n",
      "Epoch 775, Loss: 0.02166992425918579\n",
      "Epoch 776, Loss: 0.23325958847999573\n",
      "Epoch 777, Loss: 0.010035249404609203\n",
      "Epoch 778, Loss: 0.021502362564206123\n",
      "Epoch 779, Loss: 0.0009139744797721505\n",
      "Epoch 780, Loss: 0.06268806755542755\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 25, Score: 0\n",
      "Epoch 781, Loss: 5.286820396577241e-06\n",
      "Epoch 782, Loss: 0.004717996343970299\n",
      "Epoch 783, Loss: 0.003713435959070921\n",
      "Epoch 784, Loss: 0.015733996406197548\n",
      "Epoch 785, Loss: 0.0003603200020734221\n",
      "Epoch 786, Loss: 3.453513636486605e-05\n",
      "Epoch 787, Loss: 0.017341170459985733\n",
      "Epoch 788, Loss: 0.05064653977751732\n",
      "Epoch 789, Loss: 0.0008038235828280449\n",
      "Epoch 790, Loss: 0.004780737217515707\n",
      "Epoch 791, Loss: 0.01084177102893591\n",
      "Epoch 792, Loss: 0.0055330595932900906\n",
      "Epoch 793, Loss: 0.0011767045361921191\n",
      "Epoch 794, Loss: 0.0004359786689747125\n",
      "Epoch 795, Loss: 2.1666650772094727\n",
      "Epoch 796, Loss: 0.002434707013890147\n",
      "Epoch 797, Loss: 0.15926392376422882\n",
      "Epoch 798, Loss: 0.009389952756464481\n",
      "Epoch 799, Loss: 0.010372263379395008\n",
      "Epoch 800, Loss: 2.854085323633626e-05\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 801, Loss: 0.004816518165171146\n",
      "Epoch 802, Loss: 0.005808130372315645\n",
      "Epoch 803, Loss: 0.002001947956159711\n",
      "Epoch 804, Loss: 0.05711448937654495\n",
      "Epoch 805, Loss: 0.0027526470366865396\n",
      "Epoch 806, Loss: 0.015335334464907646\n",
      "Epoch 807, Loss: 0.000942711194511503\n",
      "Epoch 808, Loss: 0.021991100162267685\n",
      "Epoch 809, Loss: 0.008505594916641712\n",
      "Epoch 810, Loss: 5.438361404230818e-05\n",
      "Epoch 811, Loss: 0.03068101964890957\n",
      "Epoch 812, Loss: 0.0008587975171394646\n",
      "Epoch 813, Loss: 0.02029488794505596\n",
      "Epoch 814, Loss: 0.020252512767910957\n",
      "Epoch 815, Loss: 0.0005775933968834579\n",
      "Epoch 816, Loss: 0.019897179678082466\n",
      "Epoch 817, Loss: 0.003237992525100708\n",
      "Epoch 818, Loss: 0.0018764672568067908\n",
      "Epoch 819, Loss: 0.011078540235757828\n",
      "Epoch 820, Loss: 0.006413498427718878\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 30, Score: 0\n",
      "Epoch 821, Loss: 3.057891717617167e-07\n",
      "Epoch 822, Loss: 0.0018608378013595939\n",
      "Epoch 823, Loss: 7.57648967919522e-06\n",
      "Epoch 824, Loss: 0.0005978580447845161\n",
      "Epoch 825, Loss: 0.0026662556920200586\n",
      "Epoch 826, Loss: 0.0004211548366583884\n",
      "Epoch 827, Loss: 2.3813765048980713\n",
      "Epoch 828, Loss: 0.004010016098618507\n",
      "Epoch 829, Loss: 0.004622453823685646\n",
      "Epoch 830, Loss: 0.0012072009267285466\n",
      "Epoch 831, Loss: 0.00020427406707312912\n",
      "Epoch 832, Loss: 0.0004846013616770506\n",
      "Epoch 833, Loss: 0.034479591995477676\n",
      "Epoch 834, Loss: 0.010382208973169327\n",
      "Epoch 835, Loss: 0.007064126431941986\n",
      "Epoch 836, Loss: 0.039688773453235626\n",
      "Epoch 837, Loss: 0.0006349983159452677\n",
      "Epoch 838, Loss: 0.0006551899132318795\n",
      "Epoch 839, Loss: 0.0005962559953331947\n",
      "Epoch 840, Loss: 0.0031915982253849506\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 841, Loss: 0.01626739092171192\n",
      "Epoch 842, Loss: 0.0023060166276991367\n",
      "Epoch 843, Loss: 0.05302787572145462\n",
      "Epoch 844, Loss: 0.014470553025603294\n",
      "Epoch 845, Loss: 0.002290775766596198\n",
      "Epoch 846, Loss: 0.013361234217882156\n",
      "Epoch 847, Loss: 0.01180332526564598\n",
      "Epoch 848, Loss: 2.0900222807540558e-05\n",
      "Epoch 849, Loss: 0.0003431768564041704\n",
      "Epoch 850, Loss: 0.0023166262544691563\n",
      "Epoch 851, Loss: 0.00024974922416731715\n",
      "Epoch 852, Loss: 0.018141038715839386\n",
      "Epoch 853, Loss: 0.000699062249623239\n",
      "Epoch 854, Loss: 0.001868136809207499\n",
      "Epoch 855, Loss: 0.0018582777120172977\n",
      "Epoch 856, Loss: 0.045543018728494644\n",
      "Epoch 857, Loss: 0.0014922084519639611\n",
      "Epoch 858, Loss: 0.02481827512383461\n",
      "Epoch 859, Loss: 0.008606357499957085\n",
      "Epoch 860, Loss: 0.0053432476706802845\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 861, Loss: 3.8829862205602694e-06\n",
      "Epoch 862, Loss: 0.005888518877327442\n",
      "Epoch 863, Loss: 0.002946413354948163\n",
      "Epoch 864, Loss: 0.0025601342786103487\n",
      "Epoch 865, Loss: 0.18020053207874298\n",
      "Epoch 866, Loss: 0.0011158266570419073\n",
      "Epoch 867, Loss: 8.2066108006984e-06\n",
      "Epoch 868, Loss: 0.0011973509099334478\n",
      "Epoch 869, Loss: 6.166822004161077e-07\n",
      "Epoch 870, Loss: 0.003953445237129927\n",
      "Epoch 871, Loss: 0.0016385979251936078\n",
      "Epoch 872, Loss: 0.07603850215673447\n",
      "Epoch 873, Loss: 0.004093041177839041\n",
      "Epoch 874, Loss: 0.0015188368270173669\n",
      "Epoch 875, Loss: 0.0026878989301621914\n",
      "Epoch 876, Loss: 0.002561040688306093\n",
      "Epoch 877, Loss: 0.0038702720776200294\n",
      "Epoch 878, Loss: 0.0012330131139606237\n",
      "Epoch 879, Loss: 0.060148194432258606\n",
      "Epoch 880, Loss: 0.0024322604294866323\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 35, Score: 0\n",
      "Epoch 881, Loss: 0.005816327873617411\n",
      "Epoch 882, Loss: 0.002036645309999585\n",
      "Epoch 883, Loss: 0.11527032405138016\n",
      "Epoch 884, Loss: 7.061145879561082e-05\n",
      "Epoch 885, Loss: 4.9750098696677014e-05\n",
      "Epoch 886, Loss: 0.05466494336724281\n",
      "Epoch 887, Loss: 0.012360715307295322\n",
      "Epoch 888, Loss: 0.0024480302818119526\n",
      "Epoch 889, Loss: 0.0006114267744123936\n",
      "Epoch 890, Loss: 0.007362527772784233\n",
      "Epoch 891, Loss: 0.014360216446220875\n",
      "Epoch 892, Loss: 0.00018621022172737867\n",
      "Epoch 893, Loss: 0.015213699080049992\n",
      "Epoch 894, Loss: 0.01212477870285511\n",
      "Epoch 895, Loss: 0.005098527763038874\n",
      "Epoch 896, Loss: 0.0016393845435231924\n",
      "Epoch 897, Loss: 1.1749836630770005e-05\n",
      "Epoch 898, Loss: 2.8785931135644205e-05\n",
      "Epoch 899, Loss: 0.0028948357794433832\n",
      "Epoch 900, Loss: 0.08212219178676605\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 901, Loss: 0.0007711999933235347\n",
      "Epoch 902, Loss: 0.003405845258384943\n",
      "Epoch 903, Loss: 0.0021506818011403084\n",
      "Epoch 904, Loss: 0.0064919488504529\n",
      "Epoch 905, Loss: 0.007567964028567076\n",
      "Epoch 906, Loss: 0.007048109546303749\n",
      "Epoch 907, Loss: 1.7312265634536743\n",
      "Epoch 908, Loss: 0.0063507817685604095\n",
      "Epoch 909, Loss: 0.009340831078588963\n",
      "Epoch 910, Loss: 2.3645012378692627\n",
      "Epoch 911, Loss: 0.016977323219180107\n",
      "Epoch 912, Loss: 0.0011833015596494079\n",
      "Epoch 913, Loss: 0.009483722038567066\n",
      "Epoch 914, Loss: 0.13433729112148285\n",
      "Epoch 915, Loss: 0.0024234887678176165\n",
      "Epoch 916, Loss: 0.08237867057323456\n",
      "Epoch 917, Loss: 0.0950092002749443\n",
      "Epoch 918, Loss: 0.054295361042022705\n",
      "Epoch 919, Loss: 0.02581081911921501\n",
      "Epoch 920, Loss: 0.0002445710706524551\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 921, Loss: 0.004890192300081253\n",
      "Epoch 922, Loss: 0.04795602709054947\n",
      "Epoch 923, Loss: 0.005999394226819277\n",
      "Epoch 924, Loss: 0.0042688497342169285\n",
      "Epoch 925, Loss: 0.004060956183820963\n",
      "Epoch 926, Loss: 0.0026487845461815596\n",
      "Epoch 927, Loss: 0.0010758840944617987\n",
      "Epoch 928, Loss: 0.022212523967027664\n",
      "Epoch 929, Loss: 0.0006315185455605388\n",
      "Epoch 930, Loss: 0.04959917441010475\n",
      "Epoch 931, Loss: 0.00011071012704633176\n",
      "Epoch 932, Loss: 0.006622913759201765\n",
      "Epoch 933, Loss: 0.02181101217865944\n",
      "Epoch 934, Loss: 0.03918297588825226\n",
      "Epoch 935, Loss: 0.016420217230916023\n",
      "Epoch 936, Loss: 0.019185179844498634\n",
      "Epoch 937, Loss: 0.0033475328236818314\n",
      "Epoch 938, Loss: 0.003173843724653125\n",
      "Epoch 939, Loss: 0.009577752090990543\n",
      "Epoch 940, Loss: 0.012553210370242596\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 20, Score: 0\n",
      "Epoch 941, Loss: 0.01618414744734764\n",
      "Epoch 942, Loss: 1.7219579219818115\n",
      "Epoch 943, Loss: 0.01027560606598854\n",
      "Epoch 944, Loss: 0.00118362030480057\n",
      "Epoch 945, Loss: 9.890548972180113e-05\n",
      "Epoch 946, Loss: 0.0054363044910132885\n",
      "Epoch 947, Loss: 0.039592597633600235\n",
      "Epoch 948, Loss: 0.01065596379339695\n",
      "Epoch 949, Loss: 0.030539674684405327\n",
      "Epoch 950, Loss: 0.026563670486211777\n",
      "Epoch 951, Loss: 0.007943250238895416\n",
      "Epoch 952, Loss: 0.00045546857290901244\n",
      "Epoch 953, Loss: 0.009140865877270699\n",
      "Epoch 954, Loss: 0.024117186665534973\n",
      "Epoch 955, Loss: 0.00423322431743145\n",
      "Epoch 956, Loss: 0.0007812680560164154\n",
      "Epoch 957, Loss: 0.04100175201892853\n",
      "Epoch 958, Loss: 0.0025420247111469507\n",
      "Epoch 959, Loss: 0.00023946745204739273\n",
      "Epoch 960, Loss: 0.06560991704463959\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 34, Score: 0\n",
      "Epoch 961, Loss: 0.004776328336447477\n",
      "Epoch 962, Loss: 0.0032901617232710123\n",
      "Epoch 963, Loss: 0.003117231884971261\n",
      "Epoch 964, Loss: 0.0003285014536231756\n",
      "Epoch 965, Loss: 6.651062722085044e-05\n",
      "Epoch 966, Loss: 0.05742061138153076\n",
      "Epoch 967, Loss: 1.4075661965762265e-05\n",
      "Epoch 968, Loss: 0.0004718434647656977\n",
      "Epoch 969, Loss: 0.0003103686904069036\n",
      "Epoch 970, Loss: 0.00048523140139877796\n",
      "Epoch 971, Loss: 0.002242128364741802\n",
      "Epoch 972, Loss: 6.867555930512026e-05\n",
      "Epoch 973, Loss: 0.00105057202745229\n",
      "Epoch 974, Loss: 8.29667169455206e-06\n",
      "Epoch 975, Loss: 0.0014312798157334328\n",
      "Epoch 976, Loss: 0.00021532736718654633\n",
      "Epoch 977, Loss: 8.063300356297987e-07\n",
      "Epoch 978, Loss: 0.000256398314377293\n",
      "Epoch 979, Loss: 0.005014168564230204\n",
      "Epoch 980, Loss: 0.0005132494261488318\n",
      "Evaluating active network\n",
      "Evaluation - Steps: 64, Score: 1\n",
      "Epoch 981, Loss: 0.0422338992357254\n",
      "Epoch 982, Loss: 1.377209186553955\n",
      "Epoch 983, Loss: 0.003042433178052306\n",
      "Epoch 984, Loss: 0.004308965522795916\n",
      "Epoch 985, Loss: 0.0009255035547539592\n",
      "Epoch 986, Loss: 0.0017300333129242063\n",
      "Epoch 987, Loss: 0.11629215627908707\n",
      "Epoch 988, Loss: 0.005034853704273701\n",
      "Epoch 989, Loss: 0.0010989507427439094\n",
      "Epoch 990, Loss: 0.00022580493532586843\n",
      "Epoch 991, Loss: 0.0017814459279179573\n",
      "Epoch 992, Loss: 0.05494018644094467\n",
      "Epoch 993, Loss: 0.015441511757671833\n",
      "Epoch 994, Loss: 0.001165465684607625\n",
      "Epoch 995, Loss: 7.202488632174209e-05\n",
      "Epoch 996, Loss: 0.007328668609261513\n",
      "Epoch 997, Loss: 0.0011702971532940865\n",
      "Epoch 998, Loss: 0.0012733894400298595\n",
      "Epoch 999, Loss: 0.0005788840935565531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>evaluation_score</td><td>█▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>evaluation_steps</td><td>▂▂▁▂▂▂▁▁▁▁▂▁▁▁▃▂▄▂▂▂▃▂▇▂▇▂▂▃▂▂▃▁▂▃▂▄▂▂▂█</td></tr><tr><td>training_loss</td><td>▁▁▁█▁▁▃▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▃▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>999</td></tr><tr><td>evaluation_score</td><td>1</td></tr><tr><td>evaluation_steps</td><td>64</td></tr><tr><td>training_loss</td><td>0.00058</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">initial_base_model_run</strong> at: <a href='https://wandb.ai/pypdeveloper/snake_game_rl/runs/igo6zi8f' target=\"_blank\">https://wandb.ai/pypdeveloper/snake_game_rl/runs/igo6zi8f</a><br> View project at: <a href='https://wandb.ai/pypdeveloper/snake_game_rl' target=\"_blank\">https://wandb.ai/pypdeveloper/snake_game_rl</a><br>Synced 5 W&B file(s), 3 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250610_192233-igo6zi8f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_nn = DQN_base_ff(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE).to(device=device)\n",
    "target_nn = DQN_base_ff(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE).to(device=device)\n",
    "target_nn.load_state_dict(active_nn.state_dict())\n",
    "target_nn.requires_grad_ = False\n",
    "optimizer = optim.AdamW(active_nn.parameters(), LR)\n",
    "\n",
    "active_nn, target_nn = train(\n",
    "    active_nn=active_nn,\n",
    "    target_nn=target_nn,\n",
    "    state_action_pairs=state_action_pairs,\n",
    "    replay_memory_size=REPLAY_MEMORY_SIZE,\n",
    "    device=device,\n",
    "    loss_function=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    gamma=GAMMA,\n",
    "    epochs=EPOCHS,\n",
    "    freq_of_target_nn_update=FREQ_OF_TARGET_NN_UPDATE,\n",
    "    epsilon=EPSILON,\n",
    "    action_space=ACTION_SPACE,\n",
    "    policy=policy,\n",
    "    model_name=\"initial_base_model\",\n",
    "    model_type=\"linear\",\n",
    "    learning_rate=LR,\n",
    "    run_name=\"initial_base_model_run\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78923f73",
   "metadata": {},
   "source": [
    "### Training Scaled FF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf744659",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLAY_MEMORY_SIZE = 50000000\n",
    "HIDDEN_SIZE = 64 \n",
    "EPOCHS = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45876e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [initial_state, action, final_state, dead, reward]\n",
    "state_action_pairs = deque(maxlen=REPLAY_MEMORY_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c746d86",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(REPLAY_MEMORY_SIZE):\n\u001b[32m      5\u001b[39m     initial_state = game.get_state()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     action_pred = torch.argmax(active_nn(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m.to(device)))\n\u001b[32m      7\u001b[39m     action = policy(EPSILON, ACTION_SPACE, action_pred)\n\u001b[32m      8\u001b[39m     done = game.move_with_action(action=action)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "active_nn = DQN_scaled_ff(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE).to(device=device)\n",
    "\n",
    "game = Snake()\n",
    "for episode in range(REPLAY_MEMORY_SIZE):\n",
    "    initial_state = game.get_state()\n",
    "    action_pred = torch.argmax(active_nn(torch.tensor(initial_state, dtype=torch.float32).to(device)))\n",
    "    action = policy(EPSILON, ACTION_SPACE, action_pred)\n",
    "    done = game.move_with_action(action=action)\n",
    "    final_state = game.get_state()\n",
    "    reward = game.get_immediate_reward()\n",
    "    \n",
    "    state_action_pairs.append((initial_state, action, reward, final_state, done))\n",
    "    EPSILON *= EPSILON_DECAY\n",
    "\n",
    "    if done == 1:\n",
    "        game = Snake()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_nn = DQN_scaled_ff(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE).to(device=device)\n",
    "target_nn = DQN_scaled_ff(INPUT_SIZE, OUTPUT_SIZE, HIDDEN_SIZE).to(device=device)\n",
    "target_nn.load_state_dict(active_nn.state_dict())\n",
    "target_nn.requires_grad_ = False\n",
    "optimizer = optim.AdamW(active_nn.parameters(), LR)\n",
    "\n",
    "active_nn, target_nn = train(\n",
    "    active_nn=active_nn,\n",
    "    target_nn=target_nn,\n",
    "    state_action_pairs=state_action_pairs,\n",
    "    replay_memory_size=REPLAY_MEMORY_SIZE,\n",
    "    device=device,\n",
    "    loss_function=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    gamma=GAMMA,\n",
    "    epochs=EPOCHS,\n",
    "    freq_of_target_nn_update=FREQ_OF_TARGET_NN_UPDATE,\n",
    "    epsilon=EPSILON,\n",
    "    action_space=ACTION_SPACE,\n",
    "    policy=policy,\n",
    "    model_name=\"scaled_ff_model\",\n",
    "    model_type=\"scaled_ff\",\n",
    "    learning_rate=LR,\n",
    "    run_name=\"scaled_ff_model_run\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75d05bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_snake_game",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
